{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e8b499f-f00a-4ed4-a91d-af4b49cb1ad8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-22T07:03:25.559251Z",
     "iopub.status.busy": "2022-11-22T07:03:25.559251Z",
     "iopub.status.idle": "2022-11-22T07:03:35.517962Z",
     "shell.execute_reply": "2022-11-22T07:03:35.517962Z",
     "shell.execute_reply.started": "2022-11-22T07:03:25.559251Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hyperopt in c:\\ananconda3\\lib\\site-packages (0.2.7)\n",
      "Requirement already satisfied: six in c:\\ananconda3\\lib\\site-packages (from hyperopt) (1.16.0)\n",
      "Requirement already satisfied: scipy in c:\\ananconda3\\lib\\site-packages (from hyperopt) (1.9.3)\n",
      "Requirement already satisfied: numpy in c:\\ananconda3\\lib\\site-packages (from hyperopt) (1.21.5)\n",
      "Requirement already satisfied: py4j in c:\\ananconda3\\lib\\site-packages (from hyperopt) (0.10.9.7)\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\ananconda3\\lib\\site-packages (from hyperopt) (2.8.4)\n",
      "Requirement already satisfied: tqdm in c:\\ananconda3\\lib\\site-packages (from hyperopt) (4.64.1)\n",
      "Requirement already satisfied: cloudpickle in c:\\ananconda3\\lib\\site-packages (from hyperopt) (2.0.0)\n",
      "Requirement already satisfied: future in c:\\ananconda3\\lib\\site-packages (from hyperopt) (0.18.2)\n",
      "Requirement already satisfied: colorama in c:\\ananconda3\\lib\\site-packages (from tqdm->hyperopt) (0.4.5)\n",
      "Requirement already satisfied: imblearn in c:\\ananconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\ananconda3\\lib\\site-packages (from imblearn) (0.9.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\ananconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.21.5)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in c:\\ananconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.1.3)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\ananconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.1.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\ananconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.9.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\ananconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (2.2.0)\n",
      "Requirement already satisfied: missingno in c:\\ananconda3\\lib\\site-packages (0.5.1)\n",
      "Requirement already satisfied: matplotlib in c:\\ananconda3\\lib\\site-packages (from missingno) (3.5.3)\n",
      "Requirement already satisfied: scipy in c:\\ananconda3\\lib\\site-packages (from missingno) (1.9.3)\n",
      "Requirement already satisfied: seaborn in c:\\ananconda3\\lib\\site-packages (from missingno) (0.12.0)\n",
      "Requirement already satisfied: numpy in c:\\ananconda3\\lib\\site-packages (from missingno) (1.21.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\ananconda3\\lib\\site-packages (from matplotlib->missingno) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\ananconda3\\lib\\site-packages (from matplotlib->missingno) (9.2.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\ananconda3\\lib\\site-packages (from matplotlib->missingno) (4.25.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\ananconda3\\lib\\site-packages (from matplotlib->missingno) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\ananconda3\\lib\\site-packages (from matplotlib->missingno) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\ananconda3\\lib\\site-packages (from matplotlib->missingno) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\ananconda3\\lib\\site-packages (from matplotlib->missingno) (2.8.2)\n",
      "Requirement already satisfied: pandas>=0.25 in c:\\ananconda3\\lib\\site-packages (from seaborn->missingno) (1.4.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\ananconda3\\lib\\site-packages (from pandas>=0.25->seaborn->missingno) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\ananconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->missingno) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install hyperopt\n",
    "!pip install imblearn\n",
    "!pip install missingno\n",
    "import missingno as msno\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "from IPython.display import Image\n",
    "\n",
    "%config Completer.use_jedi = False\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "mpl.rc('font', family = 'D2coding')\n",
    "mpl.rc('axes', unicode_minus = False)\n",
    "\n",
    "sns.set(font = 'D2coding', rc = {'axes.unicode_minus':False}, style = 'darkgrid')\n",
    "plt.rc('figure', figsize = (10, 8))\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5920c65d-bdd8-4194-b309-560e7a683986",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-22T07:03:35.534925Z",
     "iopub.status.busy": "2022-11-22T07:03:35.534925Z",
     "iopub.status.idle": "2022-11-22T07:03:35.833240Z",
     "shell.execute_reply": "2022-11-22T07:03:35.833240Z",
     "shell.execute_reply.started": "2022-11-22T07:03:35.534925Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.metrics import f1_score, confusion_matrix, precision_recall_curve, roc_curve, classification_report\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "\n",
    "# 평가지표 분류\n",
    "def get_clf_eval(y_test, pred = None, pred_proba = None):\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    f1 = f1_score(y_test, pred)\n",
    "    roc_auc = roc_auc_score(y_test, pred_proba)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    print('정확도 : {:.4f}, 정밀도 : {:.4f}, 재현율 : {:.4f}, F1 : {:.4f}, AUC : {:.4f}'.\n",
    "          format(accuracy, precision, recall, f1, roc_auc))\n",
    "\n",
    "# 재현율과 정밀도의 시각화\n",
    "def precision_recall_curve_plot(y_test, pred_proba_c1):\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_test, pred_proba_c1)\n",
    "    \n",
    "    plt.figure(figsize = (10, 7))\n",
    "    plt.rc('font', family = 'D2coding')\n",
    "    threshold_boundary = thresholds.shape[0]\n",
    "    a = thresholds[precisions[0:threshold_boundary] == recalls[0:threshold_boundary]]\n",
    "    loc = np.where(thresholds == a[0])[0][0]\n",
    "    plt.plot(thresholds, precisions[0:threshold_boundary], linestyle = '--', label = 'precision')\n",
    "    plt.plot(thresholds, recalls[0:threshold_boundary], label = 'recall')\n",
    "    plt.scatter(thresholds[loc], precisions[loc], c = 'black', s = 60)\n",
    "    plt.text(0.02 + thresholds[loc], precisions[loc], '임계값 : {:.3f}'.format(thresholds[loc]), size = 15)\n",
    "    \n",
    "    start, end = plt.xlim()\n",
    "    plt.xticks(np.round(np.arange(start, end, 0.1), 2), size = 15)\n",
    "    plt.xlabel('Threshold value', size = 15); plt.ylabel('Precision and Recall value', size = 15)\n",
    "    plt.legend()\n",
    "    plt.rc('legend', fontsize = 15)\n",
    "    plt.rc('ytick', labelsize = 15)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "# 임계값 조정 함수\n",
    "def get_clf_eval_thres(y_test, pred_po, threshold, f1_show=False, auc_show=False):\n",
    "    eval_df = pd.DataFrame()\n",
    "    \n",
    "    for thres in threshold:\n",
    "        # threshold에 따른 예측 분류 값\n",
    "        binarizer = Binarizer(threshold = thres)\n",
    "        binarizer.fit(pred_po)\n",
    "        thres_pred = binarizer.transform(pred_po)\n",
    "        \n",
    "        # 평가지표  \n",
    "        accuracy = accuracy_score(y_test, thres_pred)\n",
    "        precision = precision_score(y_test, thres_pred)\n",
    "        recall = recall_score(y_test, thres_pred)\n",
    "        f1 = f1_score(y_test, thres_pred)\n",
    "        auc = roc_auc_score(y_test, pred_po)\n",
    "        \n",
    "        # 데이터 프레임 형태\n",
    "        eval_lst = np.array([accuracy, precision, recall, f1, auc]).reshape(-1,1)\n",
    "        temp = pd.DataFrame(eval_lst, columns=[thres], \n",
    "                            index = [\"정확도\", \"정밀도\", \"재현율\", \"F1스코어\", \"AUC\"])\n",
    "        eval_df = pd.concat([eval_df,temp], axis=1)\n",
    "        \n",
    "    eval_df.columns.names = [\"임계값\"]\n",
    "    \n",
    "    if f1_show == False:\n",
    "        eval_df.drop(\"F1스코어\", axis=0, inplace=True)\n",
    "        \n",
    "    if auc_show == False:\n",
    "        eval_df.drop(\"AUC\", axis=0, inplace=True)\n",
    "        \n",
    "    return round(eval_df, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f35cacd-7731-45e6-81b9-579c9ea1b30e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-22T07:03:35.835244Z",
     "iopub.status.busy": "2022-11-22T07:03:35.835244Z",
     "iopub.status.idle": "2022-11-22T07:03:35.929238Z",
     "shell.execute_reply": "2022-11-22T07:03:35.928232Z",
     "shell.execute_reply.started": "2022-11-22T07:03:35.835244Z"
    }
   },
   "outputs": [],
   "source": [
    "sample = pd.read_csv('C:/k_digital/source/data/open/sample_submission.csv')\n",
    "test = pd.read_csv('C:/k_digital/source/data/open/test.csv')\n",
    "train = pd.read_csv('C:/k_digital/source/data/open/train.csv')\n",
    "oil_info = pd.read_csv('C:/k_digital/source/data/open/data_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5e337c7-b5e5-4471-bafa-1234c53b61fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-22T07:05:53.764935Z",
     "iopub.status.busy": "2022-11-22T07:05:53.763937Z",
     "iopub.status.idle": "2022-11-22T07:05:53.786876Z",
     "shell.execute_reply": "2022-11-22T07:05:53.786876Z",
     "shell.execute_reply.started": "2022-11-22T07:05:53.764935Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>COMPONENT_ARBITRARY</th>\n",
       "      <th>ANONYMOUS_1</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>ANONYMOUS_2</th>\n",
       "      <th>AG</th>\n",
       "      <th>CO</th>\n",
       "      <th>CR</th>\n",
       "      <th>CU</th>\n",
       "      <th>FE</th>\n",
       "      <th>H2O</th>\n",
       "      <th>MN</th>\n",
       "      <th>MO</th>\n",
       "      <th>NI</th>\n",
       "      <th>PQINDEX</th>\n",
       "      <th>TI</th>\n",
       "      <th>V</th>\n",
       "      <th>V40</th>\n",
       "      <th>ZN</th>\n",
       "      <th>Y_LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_00000</td>\n",
       "      <td>2</td>\n",
       "      <td>1486</td>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>78</td>\n",
       "      <td>888</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>8504</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_00001</td>\n",
       "      <td>1</td>\n",
       "      <td>1350</td>\n",
       "      <td>14</td>\n",
       "      <td>375</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>652</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_00002</td>\n",
       "      <td>1</td>\n",
       "      <td>2415</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72.6</td>\n",
       "      <td>412</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_00003</td>\n",
       "      <td>2</td>\n",
       "      <td>7389</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>133.3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_00004</td>\n",
       "      <td>2</td>\n",
       "      <td>3954</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>217</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>133.1</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14090</th>\n",
       "      <td>TRAIN_14090</td>\n",
       "      <td>2</td>\n",
       "      <td>1616</td>\n",
       "      <td>7</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>135.4</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14091</th>\n",
       "      <td>TRAIN_14091</td>\n",
       "      <td>0</td>\n",
       "      <td>2784</td>\n",
       "      <td>6</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>224</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>117.5</td>\n",
       "      <td>1408</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14092</th>\n",
       "      <td>TRAIN_14092</td>\n",
       "      <td>2</td>\n",
       "      <td>1788</td>\n",
       "      <td>1</td>\n",
       "      <td>550</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>415</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>645</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1301</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14093</th>\n",
       "      <td>TRAIN_14093</td>\n",
       "      <td>1</td>\n",
       "      <td>2498</td>\n",
       "      <td>2</td>\n",
       "      <td>550</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44.3</td>\n",
       "      <td>652</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14094</th>\n",
       "      <td>TRAIN_14094</td>\n",
       "      <td>1</td>\n",
       "      <td>1902</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>612</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14095 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID  COMPONENT_ARBITRARY  ANONYMOUS_1  YEAR  ANONYMOUS_2  AG  \\\n",
       "0      TRAIN_00000                    2         1486     4          200   0   \n",
       "1      TRAIN_00001                    1         1350    14          375   0   \n",
       "2      TRAIN_00002                    1         2415     8          200   0   \n",
       "3      TRAIN_00003                    2         7389     3          200   0   \n",
       "4      TRAIN_00004                    2         3954     8          200   0   \n",
       "...            ...                  ...          ...   ...          ...  ..   \n",
       "14090  TRAIN_14090                    2         1616     7          200   0   \n",
       "14091  TRAIN_14091                    0         2784     6          200   0   \n",
       "14092  TRAIN_14092                    2         1788     1          550   0   \n",
       "14093  TRAIN_14093                    1         2498     2          550   0   \n",
       "14094  TRAIN_14094                    1         1902     5          200   0   \n",
       "\n",
       "       CO  CR   CU   FE  H2O  MN   MO  NI  PQINDEX  TI  V    V40    ZN  \\\n",
       "0       0  13   78  888  0.0  16    1   6     8504   5  0  154.0    75   \n",
       "1       0   0   31    2  0.0   0    0   0       19   0  0   44.0   652   \n",
       "2       0   1    2    4  0.0   0    0   0       17   0  0   72.6   412   \n",
       "3       0   0    1   37  0.0   1    0   0       44   0  0  133.3     7   \n",
       "4       0   0    0   71  0.0   0    0   0      217   0  0  133.1   128   \n",
       "...    ..  ..  ...  ...  ...  ..  ...  ..      ...  .. ..    ...   ...   \n",
       "14090   0   0    3   23  0.0   0    0   0       35   0  0  135.4    16   \n",
       "14091   0   0    2   12  0.0   0  224   0        9   0  0  117.5  1408   \n",
       "14092   0   4    7  415  0.0   7   10   1      645   0  0   54.0  1301   \n",
       "14093   0   0  170   19  0.0   0    1   0       11   0  0   44.3   652   \n",
       "14094   0   0  110   10  0.0   0    0   0       81   2  0   47.0   612   \n",
       "\n",
       "       Y_LABEL  \n",
       "0            0  \n",
       "1            0  \n",
       "2            1  \n",
       "3            0  \n",
       "4            0  \n",
       "...        ...  \n",
       "14090        0  \n",
       "14091        0  \n",
       "14092        0  \n",
       "14093        0  \n",
       "14094        0  \n",
       "\n",
       "[14095 rows x 20 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train  = train[['ID', 'COMPONENT_ARBITRARY', 'ANONYMOUS_1', 'YEAR' , 'ANONYMOUS_2', \n",
    "   'AG', 'CO', 'CR', 'CU', 'FE', 'H2O', \n",
    "   'MN', 'MO', 'NI', 'PQINDEX', 'TI', 'V', 'V40', 'ZN', 'Y_LABEL']]\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d58ca56-3807-43ec-95a4-adc65a8b4651",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-22T07:05:58.833014Z",
     "iopub.status.busy": "2022-11-22T07:05:58.833014Z",
     "iopub.status.idle": "2022-11-22T07:05:58.873904Z",
     "shell.execute_reply": "2022-11-22T07:05:58.872906Z",
     "shell.execute_reply.started": "2022-11-22T07:05:58.833014Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMPONENT_ARBITRARY</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>ANONYMOUS_1</th>\n",
       "      <th>ANONYMOUS_2</th>\n",
       "      <th>AG</th>\n",
       "      <th>CO</th>\n",
       "      <th>CR</th>\n",
       "      <th>CU</th>\n",
       "      <th>FE</th>\n",
       "      <th>H2O</th>\n",
       "      <th>MN</th>\n",
       "      <th>MO</th>\n",
       "      <th>NI</th>\n",
       "      <th>PQINDEX</th>\n",
       "      <th>TI</th>\n",
       "      <th>V</th>\n",
       "      <th>V40</th>\n",
       "      <th>ZN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TRAIN_00000</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.393763</td>\n",
       "      <td>-0.340760</td>\n",
       "      <td>-0.150214</td>\n",
       "      <td>-0.089633</td>\n",
       "      <td>0.339245</td>\n",
       "      <td>0.336858</td>\n",
       "      <td>1.331290</td>\n",
       "      <td>-0.041588</td>\n",
       "      <td>1.186914</td>\n",
       "      <td>-0.384284</td>\n",
       "      <td>1.384414</td>\n",
       "      <td>5.293270</td>\n",
       "      <td>0.622282</td>\n",
       "      <td>-0.10655</td>\n",
       "      <td>0.899892</td>\n",
       "      <td>-0.966002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAIN_00001</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>-0.426022</td>\n",
       "      <td>-0.022576</td>\n",
       "      <td>-0.150214</td>\n",
       "      <td>-0.089633</td>\n",
       "      <td>-0.115388</td>\n",
       "      <td>-0.027612</td>\n",
       "      <td>-0.330406</td>\n",
       "      <td>-0.041588</td>\n",
       "      <td>-0.250456</td>\n",
       "      <td>-0.400998</td>\n",
       "      <td>-0.191804</td>\n",
       "      <td>-0.259244</td>\n",
       "      <td>-0.102635</td>\n",
       "      <td>-0.10655</td>\n",
       "      <td>-1.317376</td>\n",
       "      <td>0.119147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAIN_00002</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.173409</td>\n",
       "      <td>-0.340760</td>\n",
       "      <td>-0.150214</td>\n",
       "      <td>-0.089633</td>\n",
       "      <td>-0.080416</td>\n",
       "      <td>-0.252497</td>\n",
       "      <td>-0.326655</td>\n",
       "      <td>-0.041588</td>\n",
       "      <td>-0.250456</td>\n",
       "      <td>-0.400998</td>\n",
       "      <td>-0.191804</td>\n",
       "      <td>-0.260552</td>\n",
       "      <td>-0.102635</td>\n",
       "      <td>-0.10655</td>\n",
       "      <td>-0.740886</td>\n",
       "      <td>-0.332215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAIN_00003</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.006399</td>\n",
       "      <td>-0.340760</td>\n",
       "      <td>-0.150214</td>\n",
       "      <td>-0.089633</td>\n",
       "      <td>-0.115388</td>\n",
       "      <td>-0.260252</td>\n",
       "      <td>-0.264764</td>\n",
       "      <td>-0.041588</td>\n",
       "      <td>-0.160621</td>\n",
       "      <td>-0.400998</td>\n",
       "      <td>-0.191804</td>\n",
       "      <td>-0.242884</td>\n",
       "      <td>-0.102635</td>\n",
       "      <td>-0.10655</td>\n",
       "      <td>0.482642</td>\n",
       "      <td>-1.093888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAIN_00004</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.191634</td>\n",
       "      <td>-0.340760</td>\n",
       "      <td>-0.150214</td>\n",
       "      <td>-0.089633</td>\n",
       "      <td>-0.115388</td>\n",
       "      <td>-0.268007</td>\n",
       "      <td>-0.200996</td>\n",
       "      <td>-0.041588</td>\n",
       "      <td>-0.250456</td>\n",
       "      <td>-0.400998</td>\n",
       "      <td>-0.191804</td>\n",
       "      <td>-0.129674</td>\n",
       "      <td>-0.102635</td>\n",
       "      <td>-0.10655</td>\n",
       "      <td>0.478611</td>\n",
       "      <td>-0.866326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAIN_14090</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.362928</td>\n",
       "      <td>-0.340760</td>\n",
       "      <td>-0.150214</td>\n",
       "      <td>-0.089633</td>\n",
       "      <td>-0.115388</td>\n",
       "      <td>-0.244743</td>\n",
       "      <td>-0.291021</td>\n",
       "      <td>-0.041588</td>\n",
       "      <td>-0.250456</td>\n",
       "      <td>-0.400998</td>\n",
       "      <td>-0.191804</td>\n",
       "      <td>-0.248773</td>\n",
       "      <td>-0.102635</td>\n",
       "      <td>-0.10655</td>\n",
       "      <td>0.524972</td>\n",
       "      <td>-1.076961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAIN_14091</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.085884</td>\n",
       "      <td>-0.340760</td>\n",
       "      <td>-0.150214</td>\n",
       "      <td>-0.089633</td>\n",
       "      <td>-0.115388</td>\n",
       "      <td>-0.252497</td>\n",
       "      <td>-0.311651</td>\n",
       "      <td>-0.041588</td>\n",
       "      <td>-0.250456</td>\n",
       "      <td>3.342831</td>\n",
       "      <td>-0.191804</td>\n",
       "      <td>-0.265787</td>\n",
       "      <td>-0.102635</td>\n",
       "      <td>-0.10655</td>\n",
       "      <td>0.164162</td>\n",
       "      <td>1.540935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAIN_14092</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.322130</td>\n",
       "      <td>0.295608</td>\n",
       "      <td>-0.150214</td>\n",
       "      <td>-0.089633</td>\n",
       "      <td>0.024499</td>\n",
       "      <td>-0.213724</td>\n",
       "      <td>0.444177</td>\n",
       "      <td>-0.041588</td>\n",
       "      <td>0.378393</td>\n",
       "      <td>-0.233862</td>\n",
       "      <td>0.070899</td>\n",
       "      <td>0.150406</td>\n",
       "      <td>-0.102635</td>\n",
       "      <td>-0.10655</td>\n",
       "      <td>-1.115806</td>\n",
       "      <td>1.339703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAIN_14093</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.153722</td>\n",
       "      <td>0.295608</td>\n",
       "      <td>-0.150214</td>\n",
       "      <td>-0.089633</td>\n",
       "      <td>-0.115388</td>\n",
       "      <td>1.050289</td>\n",
       "      <td>-0.298523</td>\n",
       "      <td>-0.041588</td>\n",
       "      <td>-0.250456</td>\n",
       "      <td>-0.384284</td>\n",
       "      <td>-0.191804</td>\n",
       "      <td>-0.264479</td>\n",
       "      <td>-0.102635</td>\n",
       "      <td>-0.10655</td>\n",
       "      <td>-1.311328</td>\n",
       "      <td>0.119147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAIN_14094</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.295090</td>\n",
       "      <td>-0.340760</td>\n",
       "      <td>-0.150214</td>\n",
       "      <td>-0.089633</td>\n",
       "      <td>-0.115388</td>\n",
       "      <td>0.585008</td>\n",
       "      <td>-0.315402</td>\n",
       "      <td>-0.041588</td>\n",
       "      <td>-0.250456</td>\n",
       "      <td>-0.400998</td>\n",
       "      <td>-0.191804</td>\n",
       "      <td>-0.218671</td>\n",
       "      <td>0.187332</td>\n",
       "      <td>-0.10655</td>\n",
       "      <td>-1.256905</td>\n",
       "      <td>0.043920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14095 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             COMPONENT_ARBITRARY  YEAR  ANONYMOUS_1  ANONYMOUS_2        AG  \\\n",
       "ID                                                                           \n",
       "TRAIN_00000                    2     4    -0.393763    -0.340760 -0.150214   \n",
       "TRAIN_00001                    1    14    -0.426022    -0.022576 -0.150214   \n",
       "TRAIN_00002                    1     8    -0.173409    -0.340760 -0.150214   \n",
       "TRAIN_00003                    2     3     1.006399    -0.340760 -0.150214   \n",
       "TRAIN_00004                    2     8     0.191634    -0.340760 -0.150214   \n",
       "...                          ...   ...          ...          ...       ...   \n",
       "TRAIN_14090                    2     7    -0.362928    -0.340760 -0.150214   \n",
       "TRAIN_14091                    0     6    -0.085884    -0.340760 -0.150214   \n",
       "TRAIN_14092                    2     1    -0.322130     0.295608 -0.150214   \n",
       "TRAIN_14093                    1     2    -0.153722     0.295608 -0.150214   \n",
       "TRAIN_14094                    1     5    -0.295090    -0.340760 -0.150214   \n",
       "\n",
       "                   CO        CR        CU        FE       H2O        MN  \\\n",
       "ID                                                                        \n",
       "TRAIN_00000 -0.089633  0.339245  0.336858  1.331290 -0.041588  1.186914   \n",
       "TRAIN_00001 -0.089633 -0.115388 -0.027612 -0.330406 -0.041588 -0.250456   \n",
       "TRAIN_00002 -0.089633 -0.080416 -0.252497 -0.326655 -0.041588 -0.250456   \n",
       "TRAIN_00003 -0.089633 -0.115388 -0.260252 -0.264764 -0.041588 -0.160621   \n",
       "TRAIN_00004 -0.089633 -0.115388 -0.268007 -0.200996 -0.041588 -0.250456   \n",
       "...               ...       ...       ...       ...       ...       ...   \n",
       "TRAIN_14090 -0.089633 -0.115388 -0.244743 -0.291021 -0.041588 -0.250456   \n",
       "TRAIN_14091 -0.089633 -0.115388 -0.252497 -0.311651 -0.041588 -0.250456   \n",
       "TRAIN_14092 -0.089633  0.024499 -0.213724  0.444177 -0.041588  0.378393   \n",
       "TRAIN_14093 -0.089633 -0.115388  1.050289 -0.298523 -0.041588 -0.250456   \n",
       "TRAIN_14094 -0.089633 -0.115388  0.585008 -0.315402 -0.041588 -0.250456   \n",
       "\n",
       "                   MO        NI   PQINDEX        TI        V       V40  \\\n",
       "ID                                                                       \n",
       "TRAIN_00000 -0.384284  1.384414  5.293270  0.622282 -0.10655  0.899892   \n",
       "TRAIN_00001 -0.400998 -0.191804 -0.259244 -0.102635 -0.10655 -1.317376   \n",
       "TRAIN_00002 -0.400998 -0.191804 -0.260552 -0.102635 -0.10655 -0.740886   \n",
       "TRAIN_00003 -0.400998 -0.191804 -0.242884 -0.102635 -0.10655  0.482642   \n",
       "TRAIN_00004 -0.400998 -0.191804 -0.129674 -0.102635 -0.10655  0.478611   \n",
       "...               ...       ...       ...       ...      ...       ...   \n",
       "TRAIN_14090 -0.400998 -0.191804 -0.248773 -0.102635 -0.10655  0.524972   \n",
       "TRAIN_14091  3.342831 -0.191804 -0.265787 -0.102635 -0.10655  0.164162   \n",
       "TRAIN_14092 -0.233862  0.070899  0.150406 -0.102635 -0.10655 -1.115806   \n",
       "TRAIN_14093 -0.384284 -0.191804 -0.264479 -0.102635 -0.10655 -1.311328   \n",
       "TRAIN_14094 -0.400998 -0.191804 -0.218671  0.187332 -0.10655 -1.256905   \n",
       "\n",
       "                   ZN  \n",
       "ID                     \n",
       "TRAIN_00000 -0.966002  \n",
       "TRAIN_00001  0.119147  \n",
       "TRAIN_00002 -0.332215  \n",
       "TRAIN_00003 -1.093888  \n",
       "TRAIN_00004 -0.866326  \n",
       "...               ...  \n",
       "TRAIN_14090 -1.076961  \n",
       "TRAIN_14091  1.540935  \n",
       "TRAIN_14092  1.339703  \n",
       "TRAIN_14093  0.119147  \n",
       "TRAIN_14094  0.043920  \n",
       "\n",
       "[14095 rows x 18 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_features = ['COMPONENT_ARBITRARY', 'YEAR']\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "for col in categorical_features:    \n",
    "    train[col] = le.fit_transform(train[col])\n",
    "    \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "scaled = ss.fit_transform(train.drop(['ID','COMPONENT_ARBITRARY', 'YEAR', 'Y_LABEL'], axis = 1))\n",
    "columns = ['ANONYMOUS_1', 'ANONYMOUS_2', \n",
    "   'AG', 'CO', 'CR', 'CU', 'FE', 'H2O', \n",
    "   'MN', 'MO', 'NI', 'PQINDEX', 'TI', 'V', 'V40', 'ZN']\n",
    "scaled = pd.DataFrame(scaled, columns = columns)\n",
    "scaled.head()\n",
    "\n",
    "onehot = train[['ID','COMPONENT_ARBITRARY', 'YEAR']]\n",
    "scaled = pd.concat([onehot, scaled], axis = 1).set_index('ID')\n",
    "scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd6a87c-9bb2-4cd7-a190-d6122f0daa9e",
   "metadata": {},
   "source": [
    "## train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab9fcc23-6308-4dd1-8956-77a77c5d425f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-22T07:06:42.691723Z",
     "iopub.status.busy": "2022-11-22T07:06:42.691723Z",
     "iopub.status.idle": "2022-11-22T07:06:42.707682Z",
     "shell.execute_reply": "2022-11-22T07:06:42.706684Z",
     "shell.execute_reply.started": "2022-11-22T07:06:42.691723Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled, train['Y_LABEL'], test_size = 0.2, random_state = 2022, stratify = train['Y_LABEL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de0d8b37-de5d-49c5-8ef9-da293dfab21b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-22T07:06:42.836102Z",
     "iopub.status.busy": "2022-11-22T07:06:42.836102Z",
     "iopub.status.idle": "2022-11-22T07:06:43.070670Z",
     "shell.execute_reply": "2022-11-22T07:06:43.070670Z",
     "shell.execute_reply.started": "2022-11-22T07:06:42.836102Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE 적용 전 학습용 피처/레이블 데이터 세트 :  (11276, 18) (11276,)\n",
      "SMOTE 적용 후 학습용 피처/레이블 데이터 세트 : (20628, 18) (20628,)\n",
      "SMOTE 적용 후 값의 분포 :\n",
      " 0    10314\n",
      "1    10314\n",
      "Name: Y_LABEL, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_over, y_train_over = smote.fit_resample(X_train, y_train)\n",
    "print(\"SMOTE 적용 전 학습용 피처/레이블 데이터 세트 : \", X_train.shape, y_train.shape)\n",
    "print('SMOTE 적용 후 학습용 피처/레이블 데이터 세트 :', X_train_over.shape, y_train_over.shape)\n",
    "print('SMOTE 적용 후 값의 분포 :\\n',pd.Series(y_train_over).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5f7c033-f573-4522-8598-2be2c989d693",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-22T07:09:04.640310Z",
     "iopub.status.busy": "2022-11-22T07:09:04.640310Z",
     "iopub.status.idle": "2022-11-22T07:09:04.675215Z",
     "shell.execute_reply": "2022-11-22T07:09:04.674220Z",
     "shell.execute_reply.started": "2022-11-22T07:09:04.640310Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMPONENT_ARBITRARY</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>ANONYMOUS_1</th>\n",
       "      <th>ANONYMOUS_2</th>\n",
       "      <th>AG</th>\n",
       "      <th>CO</th>\n",
       "      <th>CR</th>\n",
       "      <th>CU</th>\n",
       "      <th>FE</th>\n",
       "      <th>H2O</th>\n",
       "      <th>MN</th>\n",
       "      <th>MO</th>\n",
       "      <th>NI</th>\n",
       "      <th>PQINDEX</th>\n",
       "      <th>TI</th>\n",
       "      <th>V</th>\n",
       "      <th>V40</th>\n",
       "      <th>ZN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TRAIN_06576</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.338734</td>\n",
       "      <td>-0.340760</td>\n",
       "      <td>-0.150214</td>\n",
       "      <td>-0.089633</td>\n",
       "      <td>-0.010473</td>\n",
       "      <td>-0.252497</td>\n",
       "      <td>-0.287270</td>\n",
       "      <td>-0.041588</td>\n",
       "      <td>-0.250456</td>\n",
       "      <td>-0.400998</td>\n",
       "      <td>-0.191804</td>\n",
       "      <td>-0.262516</td>\n",
       "      <td>-0.102635</td>\n",
       "      <td>-0.10655</td>\n",
       "      <td>-0.243009</td>\n",
       "      <td>1.621804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAIN_05159</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.278487</td>\n",
       "      <td>-0.340760</td>\n",
       "      <td>-0.150214</td>\n",
       "      <td>-0.089633</td>\n",
       "      <td>0.024499</td>\n",
       "      <td>-0.205969</td>\n",
       "      <td>-0.020948</td>\n",
       "      <td>-0.041588</td>\n",
       "      <td>0.198722</td>\n",
       "      <td>-0.400998</td>\n",
       "      <td>0.070899</td>\n",
       "      <td>0.507049</td>\n",
       "      <td>-0.102635</td>\n",
       "      <td>-0.10655</td>\n",
       "      <td>0.383873</td>\n",
       "      <td>-1.052513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAIN_06330</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.464922</td>\n",
       "      <td>-0.002576</td>\n",
       "      <td>-0.150214</td>\n",
       "      <td>-0.089633</td>\n",
       "      <td>-0.045445</td>\n",
       "      <td>-0.244743</td>\n",
       "      <td>-0.180366</td>\n",
       "      <td>-0.041588</td>\n",
       "      <td>-0.160621</td>\n",
       "      <td>-0.350857</td>\n",
       "      <td>-0.191804</td>\n",
       "      <td>-0.245501</td>\n",
       "      <td>-0.102635</td>\n",
       "      <td>-0.10655</td>\n",
       "      <td>-0.988817</td>\n",
       "      <td>1.270119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAIN_06953</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.288449</td>\n",
       "      <td>-0.340760</td>\n",
       "      <td>-0.150214</td>\n",
       "      <td>-0.089633</td>\n",
       "      <td>-0.080416</td>\n",
       "      <td>0.546235</td>\n",
       "      <td>-0.306025</td>\n",
       "      <td>-0.041588</td>\n",
       "      <td>0.019051</td>\n",
       "      <td>-0.384284</td>\n",
       "      <td>-0.191804</td>\n",
       "      <td>-0.261207</td>\n",
       "      <td>-0.102635</td>\n",
       "      <td>-0.10655</td>\n",
       "      <td>-1.539102</td>\n",
       "      <td>-0.871968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAIN_00428</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.327349</td>\n",
       "      <td>-0.340760</td>\n",
       "      <td>-0.150214</td>\n",
       "      <td>-0.089633</td>\n",
       "      <td>-0.115388</td>\n",
       "      <td>-0.252497</td>\n",
       "      <td>-0.304149</td>\n",
       "      <td>-0.041588</td>\n",
       "      <td>-0.160621</td>\n",
       "      <td>3.209123</td>\n",
       "      <td>-0.191804</td>\n",
       "      <td>-0.261207</td>\n",
       "      <td>-0.102635</td>\n",
       "      <td>-0.10655</td>\n",
       "      <td>0.458454</td>\n",
       "      <td>1.177966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAIN_01120</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.250260</td>\n",
       "      <td>-0.340760</td>\n",
       "      <td>-0.150214</td>\n",
       "      <td>-0.089633</td>\n",
       "      <td>-0.010473</td>\n",
       "      <td>-0.198214</td>\n",
       "      <td>0.080329</td>\n",
       "      <td>-0.041588</td>\n",
       "      <td>0.019051</td>\n",
       "      <td>-0.317430</td>\n",
       "      <td>-0.191804</td>\n",
       "      <td>-0.197731</td>\n",
       "      <td>-0.102635</td>\n",
       "      <td>-0.10655</td>\n",
       "      <td>0.645914</td>\n",
       "      <td>-0.676378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAIN_12553</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.176967</td>\n",
       "      <td>-0.340760</td>\n",
       "      <td>-0.150214</td>\n",
       "      <td>-0.089633</td>\n",
       "      <td>-0.115388</td>\n",
       "      <td>-0.182705</td>\n",
       "      <td>-0.319153</td>\n",
       "      <td>-0.041588</td>\n",
       "      <td>-0.250456</td>\n",
       "      <td>-0.400998</td>\n",
       "      <td>-0.191804</td>\n",
       "      <td>-0.267096</td>\n",
       "      <td>-0.102635</td>\n",
       "      <td>-0.10655</td>\n",
       "      <td>-1.301250</td>\n",
       "      <td>0.186851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAIN_01790</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.323316</td>\n",
       "      <td>-0.340760</td>\n",
       "      <td>-0.150214</td>\n",
       "      <td>-0.089633</td>\n",
       "      <td>0.059471</td>\n",
       "      <td>-0.260252</td>\n",
       "      <td>0.421671</td>\n",
       "      <td>-0.041588</td>\n",
       "      <td>0.108886</td>\n",
       "      <td>-0.400998</td>\n",
       "      <td>0.070899</td>\n",
       "      <td>0.097400</td>\n",
       "      <td>0.477299</td>\n",
       "      <td>-0.10655</td>\n",
       "      <td>0.494737</td>\n",
       "      <td>-1.052513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAIN_07443</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.418432</td>\n",
       "      <td>-0.340760</td>\n",
       "      <td>-0.150214</td>\n",
       "      <td>-0.089633</td>\n",
       "      <td>-0.115388</td>\n",
       "      <td>1.050289</td>\n",
       "      <td>-0.328531</td>\n",
       "      <td>-0.041588</td>\n",
       "      <td>-0.250456</td>\n",
       "      <td>-0.400998</td>\n",
       "      <td>-0.191804</td>\n",
       "      <td>-0.262516</td>\n",
       "      <td>-0.102635</td>\n",
       "      <td>-0.10655</td>\n",
       "      <td>-1.327454</td>\n",
       "      <td>0.051442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAIN_09124</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.267338</td>\n",
       "      <td>-0.340760</td>\n",
       "      <td>-0.150214</td>\n",
       "      <td>-0.089633</td>\n",
       "      <td>-0.115388</td>\n",
       "      <td>-0.268007</td>\n",
       "      <td>-0.281643</td>\n",
       "      <td>-0.041588</td>\n",
       "      <td>-0.250456</td>\n",
       "      <td>-0.400998</td>\n",
       "      <td>-0.191804</td>\n",
       "      <td>-0.250082</td>\n",
       "      <td>-0.102635</td>\n",
       "      <td>-0.10655</td>\n",
       "      <td>0.936174</td>\n",
       "      <td>-1.084484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11276 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             COMPONENT_ARBITRARY  YEAR  ANONYMOUS_1  ANONYMOUS_2        AG  \\\n",
       "ID                                                                           \n",
       "TRAIN_06576                    0    10    -0.338734    -0.340760 -0.150214   \n",
       "TRAIN_05159                    2     8    -0.278487    -0.340760 -0.150214   \n",
       "TRAIN_06330                    2     2    -0.464922    -0.002576 -0.150214   \n",
       "TRAIN_06953                    1     1    -0.288449    -0.340760 -0.150214   \n",
       "TRAIN_00428                    0     2    -0.327349    -0.340760 -0.150214   \n",
       "...                          ...   ...          ...          ...       ...   \n",
       "TRAIN_01120                    2     7    -0.250260    -0.340760 -0.150214   \n",
       "TRAIN_12553                    1     8    -0.176967    -0.340760 -0.150214   \n",
       "TRAIN_01790                    2     6    -0.323316    -0.340760 -0.150214   \n",
       "TRAIN_07443                    1     4    -0.418432    -0.340760 -0.150214   \n",
       "TRAIN_09124                    2     6    -0.267338    -0.340760 -0.150214   \n",
       "\n",
       "                   CO        CR        CU        FE       H2O        MN  \\\n",
       "ID                                                                        \n",
       "TRAIN_06576 -0.089633 -0.010473 -0.252497 -0.287270 -0.041588 -0.250456   \n",
       "TRAIN_05159 -0.089633  0.024499 -0.205969 -0.020948 -0.041588  0.198722   \n",
       "TRAIN_06330 -0.089633 -0.045445 -0.244743 -0.180366 -0.041588 -0.160621   \n",
       "TRAIN_06953 -0.089633 -0.080416  0.546235 -0.306025 -0.041588  0.019051   \n",
       "TRAIN_00428 -0.089633 -0.115388 -0.252497 -0.304149 -0.041588 -0.160621   \n",
       "...               ...       ...       ...       ...       ...       ...   \n",
       "TRAIN_01120 -0.089633 -0.010473 -0.198214  0.080329 -0.041588  0.019051   \n",
       "TRAIN_12553 -0.089633 -0.115388 -0.182705 -0.319153 -0.041588 -0.250456   \n",
       "TRAIN_01790 -0.089633  0.059471 -0.260252  0.421671 -0.041588  0.108886   \n",
       "TRAIN_07443 -0.089633 -0.115388  1.050289 -0.328531 -0.041588 -0.250456   \n",
       "TRAIN_09124 -0.089633 -0.115388 -0.268007 -0.281643 -0.041588 -0.250456   \n",
       "\n",
       "                   MO        NI   PQINDEX        TI        V       V40  \\\n",
       "ID                                                                       \n",
       "TRAIN_06576 -0.400998 -0.191804 -0.262516 -0.102635 -0.10655 -0.243009   \n",
       "TRAIN_05159 -0.400998  0.070899  0.507049 -0.102635 -0.10655  0.383873   \n",
       "TRAIN_06330 -0.350857 -0.191804 -0.245501 -0.102635 -0.10655 -0.988817   \n",
       "TRAIN_06953 -0.384284 -0.191804 -0.261207 -0.102635 -0.10655 -1.539102   \n",
       "TRAIN_00428  3.209123 -0.191804 -0.261207 -0.102635 -0.10655  0.458454   \n",
       "...               ...       ...       ...       ...      ...       ...   \n",
       "TRAIN_01120 -0.317430 -0.191804 -0.197731 -0.102635 -0.10655  0.645914   \n",
       "TRAIN_12553 -0.400998 -0.191804 -0.267096 -0.102635 -0.10655 -1.301250   \n",
       "TRAIN_01790 -0.400998  0.070899  0.097400  0.477299 -0.10655  0.494737   \n",
       "TRAIN_07443 -0.400998 -0.191804 -0.262516 -0.102635 -0.10655 -1.327454   \n",
       "TRAIN_09124 -0.400998 -0.191804 -0.250082 -0.102635 -0.10655  0.936174   \n",
       "\n",
       "                   ZN  \n",
       "ID                     \n",
       "TRAIN_06576  1.621804  \n",
       "TRAIN_05159 -1.052513  \n",
       "TRAIN_06330  1.270119  \n",
       "TRAIN_06953 -0.871968  \n",
       "TRAIN_00428  1.177966  \n",
       "...               ...  \n",
       "TRAIN_01120 -0.676378  \n",
       "TRAIN_12553  0.186851  \n",
       "TRAIN_01790 -1.052513  \n",
       "TRAIN_07443  0.051442  \n",
       "TRAIN_09124 -1.084484  \n",
       "\n",
       "[11276 rows x 18 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d15bf82d-55d9-4437-84d4-be37db7a6307",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-22T07:07:37.114684Z",
     "iopub.status.busy": "2022-11-22T07:07:37.114684Z",
     "iopub.status.idle": "2022-11-22T07:07:39.975000Z",
     "shell.execute_reply": "2022-11-22T07:07:39.973994Z",
     "shell.execute_reply.started": "2022-11-22T07:07:37.114684Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN 정확도: 0.9117\n",
      "랜덤 포레스트 정확도: 0.9149\n",
      "결정 트리 정확도: 0.8531\n",
      "에이다부스트 정확도: 0.9138\n",
      "KNN macro macro f1 score :  0.4924272389449258\n",
      "랜덤 포레스트  macro f1 score :  0.4938655814231851\n",
      "결정 트리 macro f1 score :  0.5303920180010236\n",
      "에이다부스트 macro f1 score :  0.48155242812867777\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# 개별 ML 모델을 위한 Classifier 생성.\n",
    "knn_clf  = KNeighborsClassifier(n_neighbors=4)\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "ada_clf = AdaBoostClassifier(n_estimators=100)\n",
    "\n",
    "# 최종 Stacking 모델을 위한 Classifier생성. \n",
    "lr_final = LogisticRegression(C=10)\n",
    "\n",
    "# 개별 모델들을 학습. \n",
    "knn_clf.fit(X_train, y_train)\n",
    "rf_clf.fit(X_train , y_train)\n",
    "dt_clf.fit(X_train , y_train)\n",
    "ada_clf.fit(X_train, y_train)\n",
    "\n",
    "# 학습된 개별 모델들이 각자 반환하는 예측 데이터 셋을 생성하고 개별 모델의 정확도 측정. \n",
    "knn_pred = knn_clf.predict(X_test)\n",
    "rf_pred = rf_clf.predict(X_test)\n",
    "dt_pred = dt_clf.predict(X_test)\n",
    "ada_pred = ada_clf.predict(X_test)\n",
    "\n",
    "print('KNN 정확도: {0:.4f}'.format(accuracy_score(y_test, knn_pred)))\n",
    "print('랜덤 포레스트 정확도: {0:.4f}'.format(accuracy_score(y_test, rf_pred)))\n",
    "print('결정 트리 정확도: {0:.4f}'.format(accuracy_score(y_test, dt_pred)))\n",
    "print('에이다부스트 정확도: {0:.4f}'.format(accuracy_score(y_test, ada_pred)))\n",
    "print('KNN macro macro f1 score : ', f1_score(y_test, knn_pred, average = 'macro'))\n",
    "print('랜덤 포레스트  macro f1 score : ', f1_score(y_test, rf_pred, average = 'macro'))\n",
    "print('결정 트리 macro f1 score : ', f1_score(y_test, dt_pred, average = 'macro'))\n",
    "print('에이다부스트 macro f1 score : ', f1_score(y_test, ada_pred, average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66301a24-ebdf-4726-b140-c4c13c181b0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-22T07:07:47.074122Z",
     "iopub.status.busy": "2022-11-22T07:07:47.074122Z",
     "iopub.status.idle": "2022-11-22T07:07:47.099055Z",
     "shell.execute_reply": "2022-11-22T07:07:47.098057Z",
     "shell.execute_reply.started": "2022-11-22T07:07:47.074122Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 메타 모델의 예측 정확도: 0.9145\n"
     ]
    }
   ],
   "source": [
    "pred = np.array([knn_pred, rf_pred, dt_pred, ada_pred])\n",
    "\n",
    "# transpose를 이용해 행과 열의 위치 교환. 컬럼 레벨로 각 알고리즘의 예측 결과를 피처로 만듦. \n",
    "pred = np.transpose(pred)\n",
    "\n",
    "lr_final.fit(pred, y_test)\n",
    "final = lr_final.predict(pred)\n",
    "print('최종 메타 모델의 예측 정확도: {0:.4f}'.format(accuracy_score(y_test , final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e80204e0-36dd-4e05-8b41-64b64c687cab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-22T08:29:43.377794Z",
     "iopub.status.busy": "2022-11-22T08:29:43.376796Z",
     "iopub.status.idle": "2022-11-22T08:29:43.458577Z",
     "shell.execute_reply": "2022-11-22T08:29:43.457581Z",
     "shell.execute_reply.started": "2022-11-22T08:29:43.377794Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Int64Index([ 1611,  1612,  1613,  1614,  1615,  1616,  1617,  1618,  1619,\\n             1620,\\n            ...\\n            11266, 11267, 11268, 11269, 11270, 11271, 11272, 11273, 11274,\\n            11275],\\n           dtype='int64', length=9665)] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [57], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;66;03m#train_fold_pred는 최종 메타 모델이 사용하는 학습 데이터, test_pred_mean은 테스트 데이터\u001b[39;00m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m train_fold_pred , test_pred_mean\n\u001b[1;32m---> 33\u001b[0m knn_train, knn_test \u001b[38;5;241m=\u001b[39m \u001b[43mget_stacking_base_datasets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mknn_clf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m rf_train, rf_test \u001b[38;5;241m=\u001b[39m get_stacking_base_datasets(rf_clf, X_train, y_train, X_test, \u001b[38;5;241m7\u001b[39m)\n\u001b[0;32m     35\u001b[0m dt_train, dt_test \u001b[38;5;241m=\u001b[39m get_stacking_base_datasets(dt_clf, X_train, y_train, X_test,  \u001b[38;5;241m7\u001b[39m)    \n",
      "Cell \u001b[1;32mIn [57], line 16\u001b[0m, in \u001b[0;36mget_stacking_base_datasets\u001b[1;34m(model, X_train_n, y_train_n, X_test_n, n_folds)\u001b[0m\n\u001b[0;32m     11\u001b[0m test_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((X_test_n\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],n_folds))\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m folder_counter , (train_index, valid_index) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(kf\u001b[38;5;241m.\u001b[39msplit(X_train_n)):\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m#입력된 학습 데이터에서 기반 모델이 학습/예측할 폴드 데이터 셋 추출 \u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m     X_tr \u001b[38;5;241m=\u001b[39m \u001b[43mX_train_n\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_index\u001b[49m\u001b[43m]\u001b[49m \n\u001b[0;32m     17\u001b[0m     y_tr \u001b[38;5;241m=\u001b[39m y_train_n[train_index] \n\u001b[0;32m     18\u001b[0m     X_te \u001b[38;5;241m=\u001b[39m X_train_n[valid_index]  \n",
      "File \u001b[1;32mC:\\Ananconda3\\lib\\site-packages\\pandas\\core\\frame.py:3511\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3509\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3510\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 3511\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3513\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3514\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mC:\\Ananconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5796\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5793\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   5794\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5796\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5798\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   5799\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5800\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Ananconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5856\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[0;32m   5855\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 5856\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   5858\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   5859\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Int64Index([ 1611,  1612,  1613,  1614,  1615,  1616,  1617,  1618,  1619,\\n             1620,\\n            ...\\n            11266, 11267, 11268, 11269, 11270, 11271, 11272, 11273, 11274,\\n            11275],\\n           dtype='int64', length=9665)] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import re\n",
    "\n",
    "# 개별 기반 모델에서 최종 메타 모델이 사용할 학습 및 테스트용 데이터를 생성하기 위한 함수. \n",
    "def get_stacking_base_datasets(model, X_train_n, y_train_n, X_test_n, n_folds ):\n",
    "    # 지정된 n_folds값으로 KFold 생성.\n",
    "    kf = KFold(n_splits=n_folds, shuffle=False)\n",
    "    #추후에 메타 모델이 사용할 학습 데이터 반환을 위한 넘파이 배열 초기화 \n",
    "    train_fold_pred = np.zeros((X_train_n.shape[0] ,1 ))\n",
    "    test_pred = np.zeros((X_test_n.shape[0],n_folds))\n",
    "\n",
    "    for folder_counter , (train_index, valid_index) in enumerate(kf.split(X_train_n)):\n",
    "        #입력된 학습 데이터에서 기반 모델이 학습/예측할 폴드 데이터 셋 추출 \n",
    "\n",
    "        X_tr = X_train_n[train_index] \n",
    "        y_tr = y_train_n[train_index] \n",
    "        X_te = X_train_n[valid_index]  \n",
    "\n",
    "        #폴드 세트 내부에서 다시 만들어진 학습 데이터로 기반 모델의 학습 수행.\n",
    "        model.fit(X_tr , y_tr)       \n",
    "        #폴드 세트 내부에서 다시 만들어진 검증 데이터로 기반 모델 예측 후 데이터 저장.\n",
    "        train_fold_pred[valid_index, :] = model.predict(X_te).reshape(-1,1)\n",
    "        #입력된 원본 테스트 데이터를 폴드 세트내 학습된 기반 모델에서 예측 후 데이터 저장. \n",
    "        test_pred[:, folder_counter] = model.predict(X_test_n)\n",
    "   \n",
    "    # 폴드 세트 내에서 원본 테스트 데이터를 예측한 데이터를 평균하여 테스트 데이터로 생성 \n",
    "    test_pred_mean = np.mean(test_pred, axis=1).reshape(-1,1)    \n",
    "\n",
    "    #train_fold_pred는 최종 메타 모델이 사용하는 학습 데이터, test_pred_mean은 테스트 데이터\n",
    "    return train_fold_pred , test_pred_mean\n",
    "\n",
    "knn_train, knn_test = get_stacking_base_datasets(knn_clf, X_train, y_train, X_test, 7)\n",
    "rf_train, rf_test = get_stacking_base_datasets(rf_clf, X_train, y_train, X_test, 7)\n",
    "dt_train, dt_test = get_stacking_base_datasets(dt_clf, X_train, y_train, X_test,  7)    \n",
    "ada_train, ada_test = get_stacking_base_datasets(ada_clf, X_train, y_train, X_test, 7)\n",
    "\n",
    "Stack_final_X_train = np.concatenate((knn_train, rf_train, dt_train, ada_train), axis=1)\n",
    "Stack_final_X_test = np.concatenate((knn_test, rf_test, dt_test, ada_test), axis=1)\n",
    "print('원본 학습 피처 데이터 Shape:',X_train.shape, '원본 테스트 피처 Shape:',X_test.shape)\n",
    "print('스태킹 학습 피처 데이터 Shape:', Stack_final_X_train.shape,\n",
    "      '스태킹 테스트 피처 데이터 Shape:',Stack_final_X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a079aa88-4d14-44eb-aebb-603a60669c3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-22T08:32:41.929252Z",
     "iopub.status.busy": "2022-11-22T08:32:41.929252Z",
     "iopub.status.idle": "2022-11-22T08:32:41.949725Z",
     "shell.execute_reply": "2022-11-22T08:32:41.949725Z",
     "shell.execute_reply.started": "2022-11-22T08:32:41.929252Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2, ..., 9663, 9664, 9665])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=7, shuffle=False)\n",
    "train_index, valid_index in kf.split(X_train)\n",
    "\n",
    "train_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b79fed58-efe0-4f44-bc90-f5930e886197",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-22T07:11:21.381510Z",
     "iopub.status.busy": "2022-11-22T07:11:21.381510Z",
     "iopub.status.idle": "2022-11-22T07:11:21.399460Z",
     "shell.execute_reply": "2022-11-22T07:11:21.399460Z",
     "shell.execute_reply.started": "2022-11-22T07:11:21.381510Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1611,  1612,  1613, ..., 11273, 11274, 11275]), False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_index, valid_index in kf.split(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fadb9d0e-5e8a-424d-9bdb-90fce3daccf3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-22T08:20:37.982068Z",
     "iopub.status.busy": "2022-11-22T08:20:37.981072Z",
     "iopub.status.idle": "2022-11-22T08:20:38.008002Z",
     "shell.execute_reply": "2022-11-22T08:20:38.007036Z",
     "shell.execute_reply.started": "2022-11-22T08:20:37.982068Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1611',\n",
       " '1612',\n",
       " '1613',\n",
       " '1614',\n",
       " '1615',\n",
       " '1616',\n",
       " '1617',\n",
       " '1618',\n",
       " '1619',\n",
       " '1620',\n",
       " '1621',\n",
       " '1622',\n",
       " '1623',\n",
       " '1624',\n",
       " '1625',\n",
       " '1626',\n",
       " '1627',\n",
       " '1628',\n",
       " '1629',\n",
       " '1630',\n",
       " '1631',\n",
       " '1632',\n",
       " '1633',\n",
       " '1634',\n",
       " '1635',\n",
       " '1636',\n",
       " '1637',\n",
       " '1638',\n",
       " '1639',\n",
       " '1640',\n",
       " '1641',\n",
       " '1642',\n",
       " '1643',\n",
       " '1644',\n",
       " '1645',\n",
       " '1646',\n",
       " '1647',\n",
       " '1648',\n",
       " '1649',\n",
       " '1650',\n",
       " '1651',\n",
       " '1652',\n",
       " '1653',\n",
       " '1654',\n",
       " '1655',\n",
       " '1656',\n",
       " '1657',\n",
       " '1658',\n",
       " '1659',\n",
       " '1660',\n",
       " '1661',\n",
       " '1662',\n",
       " '1663',\n",
       " '1664',\n",
       " '1665',\n",
       " '1666',\n",
       " '1667',\n",
       " '1668',\n",
       " '1669',\n",
       " '1670',\n",
       " '1671',\n",
       " '1672',\n",
       " '1673',\n",
       " '1674',\n",
       " '1675',\n",
       " '1676',\n",
       " '1677',\n",
       " '1678',\n",
       " '1679',\n",
       " '1680',\n",
       " '1681',\n",
       " '1682',\n",
       " '1683',\n",
       " '1684',\n",
       " '1685',\n",
       " '1686',\n",
       " '1687',\n",
       " '1688',\n",
       " '1689',\n",
       " '1690',\n",
       " '1691',\n",
       " '1692',\n",
       " '1693',\n",
       " '1694',\n",
       " '1695',\n",
       " '1696',\n",
       " '1697',\n",
       " '1698',\n",
       " '1699',\n",
       " '1700',\n",
       " '1701',\n",
       " '1702',\n",
       " '1703',\n",
       " '1704',\n",
       " '1705',\n",
       " '1706',\n",
       " '1707',\n",
       " '1708',\n",
       " '1709',\n",
       " '1710',\n",
       " '1711',\n",
       " '1712',\n",
       " '1713',\n",
       " '1714',\n",
       " '1715',\n",
       " '1716',\n",
       " '1717',\n",
       " '1718',\n",
       " '1719',\n",
       " '1720',\n",
       " '1721',\n",
       " '1722',\n",
       " '1723',\n",
       " '1724',\n",
       " '1725',\n",
       " '1726',\n",
       " '1727',\n",
       " '1728',\n",
       " '1729',\n",
       " '1730',\n",
       " '1731',\n",
       " '1732',\n",
       " '1733',\n",
       " '1734',\n",
       " '1735',\n",
       " '1736',\n",
       " '1737',\n",
       " '1738',\n",
       " '1739',\n",
       " '1740',\n",
       " '1741',\n",
       " '1742',\n",
       " '1743',\n",
       " '1744',\n",
       " '1745',\n",
       " '1746',\n",
       " '1747',\n",
       " '1748',\n",
       " '1749',\n",
       " '1750',\n",
       " '1751',\n",
       " '1752',\n",
       " '1753',\n",
       " '1754',\n",
       " '1755',\n",
       " '1756',\n",
       " '1757',\n",
       " '1758',\n",
       " '1759',\n",
       " '1760',\n",
       " '1761',\n",
       " '1762',\n",
       " '1763',\n",
       " '1764',\n",
       " '1765',\n",
       " '1766',\n",
       " '1767',\n",
       " '1768',\n",
       " '1769',\n",
       " '1770',\n",
       " '1771',\n",
       " '1772',\n",
       " '1773',\n",
       " '1774',\n",
       " '1775',\n",
       " '1776',\n",
       " '1777',\n",
       " '1778',\n",
       " '1779',\n",
       " '1780',\n",
       " '1781',\n",
       " '1782',\n",
       " '1783',\n",
       " '1784',\n",
       " '1785',\n",
       " '1786',\n",
       " '1787',\n",
       " '1788',\n",
       " '1789',\n",
       " '1790',\n",
       " '1791',\n",
       " '1792',\n",
       " '1793',\n",
       " '1794',\n",
       " '1795',\n",
       " '1796',\n",
       " '1797',\n",
       " '1798',\n",
       " '1799',\n",
       " '1800',\n",
       " '1801',\n",
       " '1802',\n",
       " '1803',\n",
       " '1804',\n",
       " '1805',\n",
       " '1806',\n",
       " '1807',\n",
       " '1808',\n",
       " '1809',\n",
       " '1810',\n",
       " '1811',\n",
       " '1812',\n",
       " '1813',\n",
       " '1814',\n",
       " '1815',\n",
       " '1816',\n",
       " '1817',\n",
       " '1818',\n",
       " '1819',\n",
       " '1820',\n",
       " '1821',\n",
       " '1822',\n",
       " '1823',\n",
       " '1824',\n",
       " '1825',\n",
       " '1826',\n",
       " '1827',\n",
       " '1828',\n",
       " '1829',\n",
       " '1830',\n",
       " '1831',\n",
       " '1832',\n",
       " '1833',\n",
       " '1834',\n",
       " '1835',\n",
       " '1836',\n",
       " '1837',\n",
       " '1838',\n",
       " '1839',\n",
       " '1840',\n",
       " '1841',\n",
       " '1842',\n",
       " '1843',\n",
       " '1844',\n",
       " '1845',\n",
       " '1846',\n",
       " '1847',\n",
       " '1848',\n",
       " '1849',\n",
       " '1850',\n",
       " '1851',\n",
       " '1852',\n",
       " '1853',\n",
       " '1854',\n",
       " '1855',\n",
       " '1856',\n",
       " '1857',\n",
       " '1858',\n",
       " '1859',\n",
       " '1860',\n",
       " '1861',\n",
       " '1862',\n",
       " '1863',\n",
       " '1864',\n",
       " '1865',\n",
       " '1866',\n",
       " '1867',\n",
       " '1868',\n",
       " '1869',\n",
       " '1870',\n",
       " '1871',\n",
       " '1872',\n",
       " '1873',\n",
       " '1874',\n",
       " '1875',\n",
       " '1876',\n",
       " '1877',\n",
       " '1878',\n",
       " '1879',\n",
       " '1880',\n",
       " '1881',\n",
       " '1882',\n",
       " '1883',\n",
       " '1884',\n",
       " '1885',\n",
       " '1886',\n",
       " '1887',\n",
       " '1888',\n",
       " '1889',\n",
       " '1890',\n",
       " '1891',\n",
       " '1892',\n",
       " '1893',\n",
       " '1894',\n",
       " '1895',\n",
       " '1896',\n",
       " '1897',\n",
       " '1898',\n",
       " '1899',\n",
       " '1900',\n",
       " '1901',\n",
       " '1902',\n",
       " '1903',\n",
       " '1904',\n",
       " '1905',\n",
       " '1906',\n",
       " '1907',\n",
       " '1908',\n",
       " '1909',\n",
       " '1910',\n",
       " '1911',\n",
       " '1912',\n",
       " '1913',\n",
       " '1914',\n",
       " '1915',\n",
       " '1916',\n",
       " '1917',\n",
       " '1918',\n",
       " '1919',\n",
       " '1920',\n",
       " '1921',\n",
       " '1922',\n",
       " '1923',\n",
       " '1924',\n",
       " '1925',\n",
       " '1926',\n",
       " '1927',\n",
       " '1928',\n",
       " '1929',\n",
       " '1930',\n",
       " '1931',\n",
       " '1932',\n",
       " '1933',\n",
       " '1934',\n",
       " '1935',\n",
       " '1936',\n",
       " '1937',\n",
       " '1938',\n",
       " '1939',\n",
       " '1940',\n",
       " '1941',\n",
       " '1942',\n",
       " '1943',\n",
       " '1944',\n",
       " '1945',\n",
       " '1946',\n",
       " '1947',\n",
       " '1948',\n",
       " '1949',\n",
       " '1950',\n",
       " '1951',\n",
       " '1952',\n",
       " '1953',\n",
       " '1954',\n",
       " '1955',\n",
       " '1956',\n",
       " '1957',\n",
       " '1958',\n",
       " '1959',\n",
       " '1960',\n",
       " '1961',\n",
       " '1962',\n",
       " '1963',\n",
       " '1964',\n",
       " '1965',\n",
       " '1966',\n",
       " '1967',\n",
       " '1968',\n",
       " '1969',\n",
       " '1970',\n",
       " '1971',\n",
       " '1972',\n",
       " '1973',\n",
       " '1974',\n",
       " '1975',\n",
       " '1976',\n",
       " '1977',\n",
       " '1978',\n",
       " '1979',\n",
       " '1980',\n",
       " '1981',\n",
       " '1982',\n",
       " '1983',\n",
       " '1984',\n",
       " '1985',\n",
       " '1986',\n",
       " '1987',\n",
       " '1988',\n",
       " '1989',\n",
       " '1990',\n",
       " '1991',\n",
       " '1992',\n",
       " '1993',\n",
       " '1994',\n",
       " '1995',\n",
       " '1996',\n",
       " '1997',\n",
       " '1998',\n",
       " '1999',\n",
       " '2000',\n",
       " '2001',\n",
       " '2002',\n",
       " '2003',\n",
       " '2004',\n",
       " '2005',\n",
       " '2006',\n",
       " '2007',\n",
       " '2008',\n",
       " '2009',\n",
       " '2010',\n",
       " '2011',\n",
       " '2012',\n",
       " '2013',\n",
       " '2014',\n",
       " '2015',\n",
       " '2016',\n",
       " '2017',\n",
       " '2018',\n",
       " '2019',\n",
       " '2020',\n",
       " '2021',\n",
       " '2022',\n",
       " '2023',\n",
       " '2024',\n",
       " '2025',\n",
       " '2026',\n",
       " '2027',\n",
       " '2028',\n",
       " '2029',\n",
       " '2030',\n",
       " '2031',\n",
       " '2032',\n",
       " '2033',\n",
       " '2034',\n",
       " '2035',\n",
       " '2036',\n",
       " '2037',\n",
       " '2038',\n",
       " '2039',\n",
       " '2040',\n",
       " '2041',\n",
       " '2042',\n",
       " '2043',\n",
       " '2044',\n",
       " '2045',\n",
       " '2046',\n",
       " '2047',\n",
       " '2048',\n",
       " '2049',\n",
       " '2050',\n",
       " '2051',\n",
       " '2052',\n",
       " '2053',\n",
       " '2054',\n",
       " '2055',\n",
       " '2056',\n",
       " '2057',\n",
       " '2058',\n",
       " '2059',\n",
       " '2060',\n",
       " '2061',\n",
       " '2062',\n",
       " '2063',\n",
       " '2064',\n",
       " '2065',\n",
       " '2066',\n",
       " '2067',\n",
       " '2068',\n",
       " '2069',\n",
       " '2070',\n",
       " '2071',\n",
       " '2072',\n",
       " '2073',\n",
       " '2074',\n",
       " '2075',\n",
       " '2076',\n",
       " '2077',\n",
       " '2078',\n",
       " '2079',\n",
       " '2080',\n",
       " '2081',\n",
       " '2082',\n",
       " '2083',\n",
       " '2084',\n",
       " '2085',\n",
       " '2086',\n",
       " '2087',\n",
       " '2088',\n",
       " '2089',\n",
       " '2090',\n",
       " '2091',\n",
       " '2092',\n",
       " '2093',\n",
       " '2094',\n",
       " '2095',\n",
       " '2096',\n",
       " '2097',\n",
       " '2098',\n",
       " '2099',\n",
       " '2100',\n",
       " '2101',\n",
       " '2102',\n",
       " '2103',\n",
       " '2104',\n",
       " '2105',\n",
       " '2106',\n",
       " '2107',\n",
       " '2108',\n",
       " '2109',\n",
       " '2110',\n",
       " '2111',\n",
       " '2112',\n",
       " '2113',\n",
       " '2114',\n",
       " '2115',\n",
       " '2116',\n",
       " '2117',\n",
       " '2118',\n",
       " '2119',\n",
       " '2120',\n",
       " '2121',\n",
       " '2122',\n",
       " '2123',\n",
       " '2124',\n",
       " '2125',\n",
       " '2126',\n",
       " '2127',\n",
       " '2128',\n",
       " '2129',\n",
       " '2130',\n",
       " '2131',\n",
       " '2132',\n",
       " '2133',\n",
       " '2134',\n",
       " '2135',\n",
       " '2136',\n",
       " '2137',\n",
       " '2138',\n",
       " '2139',\n",
       " '2140',\n",
       " '2141',\n",
       " '2142',\n",
       " '2143',\n",
       " '2144',\n",
       " '2145',\n",
       " '2146',\n",
       " '2147',\n",
       " '2148',\n",
       " '2149',\n",
       " '2150',\n",
       " '2151',\n",
       " '2152',\n",
       " '2153',\n",
       " '2154',\n",
       " '2155',\n",
       " '2156',\n",
       " '2157',\n",
       " '2158',\n",
       " '2159',\n",
       " '2160',\n",
       " '2161',\n",
       " '2162',\n",
       " '2163',\n",
       " '2164',\n",
       " '2165',\n",
       " '2166',\n",
       " '2167',\n",
       " '2168',\n",
       " '2169',\n",
       " '2170',\n",
       " '2171',\n",
       " '2172',\n",
       " '2173',\n",
       " '2174',\n",
       " '2175',\n",
       " '2176',\n",
       " '2177',\n",
       " '2178',\n",
       " '2179',\n",
       " '2180',\n",
       " '2181',\n",
       " '2182',\n",
       " '2183',\n",
       " '2184',\n",
       " '2185',\n",
       " '2186',\n",
       " '2187',\n",
       " '2188',\n",
       " '2189',\n",
       " '2190',\n",
       " '2191',\n",
       " '2192',\n",
       " '2193',\n",
       " '2194',\n",
       " '2195',\n",
       " '2196',\n",
       " '2197',\n",
       " '2198',\n",
       " '2199',\n",
       " '2200',\n",
       " '2201',\n",
       " '2202',\n",
       " '2203',\n",
       " '2204',\n",
       " '2205',\n",
       " '2206',\n",
       " '2207',\n",
       " '2208',\n",
       " '2209',\n",
       " '2210',\n",
       " '2211',\n",
       " '2212',\n",
       " '2213',\n",
       " '2214',\n",
       " '2215',\n",
       " '2216',\n",
       " '2217',\n",
       " '2218',\n",
       " '2219',\n",
       " '2220',\n",
       " '2221',\n",
       " '2222',\n",
       " '2223',\n",
       " '2224',\n",
       " '2225',\n",
       " '2226',\n",
       " '2227',\n",
       " '2228',\n",
       " '2229',\n",
       " '2230',\n",
       " '2231',\n",
       " '2232',\n",
       " '2233',\n",
       " '2234',\n",
       " '2235',\n",
       " '2236',\n",
       " '2237',\n",
       " '2238',\n",
       " '2239',\n",
       " '2240',\n",
       " '2241',\n",
       " '2242',\n",
       " '2243',\n",
       " '2244',\n",
       " '2245',\n",
       " '2246',\n",
       " '2247',\n",
       " '2248',\n",
       " '2249',\n",
       " '2250',\n",
       " '2251',\n",
       " '2252',\n",
       " '2253',\n",
       " '2254',\n",
       " '2255',\n",
       " '2256',\n",
       " '2257',\n",
       " '2258',\n",
       " '2259',\n",
       " '2260',\n",
       " '2261',\n",
       " '2262',\n",
       " '2263',\n",
       " '2264',\n",
       " '2265',\n",
       " '2266',\n",
       " '2267',\n",
       " '2268',\n",
       " '2269',\n",
       " '2270',\n",
       " '2271',\n",
       " '2272',\n",
       " '2273',\n",
       " '2274',\n",
       " '2275',\n",
       " '2276',\n",
       " '2277',\n",
       " '2278',\n",
       " '2279',\n",
       " '2280',\n",
       " '2281',\n",
       " '2282',\n",
       " '2283',\n",
       " '2284',\n",
       " '2285',\n",
       " '2286',\n",
       " '2287',\n",
       " '2288',\n",
       " '2289',\n",
       " '2290',\n",
       " '2291',\n",
       " '2292',\n",
       " '2293',\n",
       " '2294',\n",
       " '2295',\n",
       " '2296',\n",
       " '2297',\n",
       " '2298',\n",
       " '2299',\n",
       " '2300',\n",
       " '2301',\n",
       " '2302',\n",
       " '2303',\n",
       " '2304',\n",
       " '2305',\n",
       " '2306',\n",
       " '2307',\n",
       " '2308',\n",
       " '2309',\n",
       " '2310',\n",
       " '2311',\n",
       " '2312',\n",
       " '2313',\n",
       " '2314',\n",
       " '2315',\n",
       " '2316',\n",
       " '2317',\n",
       " '2318',\n",
       " '2319',\n",
       " '2320',\n",
       " '2321',\n",
       " '2322',\n",
       " '2323',\n",
       " '2324',\n",
       " '2325',\n",
       " '2326',\n",
       " '2327',\n",
       " '2328',\n",
       " '2329',\n",
       " '2330',\n",
       " '2331',\n",
       " '2332',\n",
       " '2333',\n",
       " '2334',\n",
       " '2335',\n",
       " '2336',\n",
       " '2337',\n",
       " '2338',\n",
       " '2339',\n",
       " '2340',\n",
       " '2341',\n",
       " '2342',\n",
       " '2343',\n",
       " '2344',\n",
       " '2345',\n",
       " '2346',\n",
       " '2347',\n",
       " '2348',\n",
       " '2349',\n",
       " '2350',\n",
       " '2351',\n",
       " '2352',\n",
       " '2353',\n",
       " '2354',\n",
       " '2355',\n",
       " '2356',\n",
       " '2357',\n",
       " '2358',\n",
       " '2359',\n",
       " '2360',\n",
       " '2361',\n",
       " '2362',\n",
       " '2363',\n",
       " '2364',\n",
       " '2365',\n",
       " '2366',\n",
       " '2367',\n",
       " '2368',\n",
       " '2369',\n",
       " '2370',\n",
       " '2371',\n",
       " '2372',\n",
       " '2373',\n",
       " '2374',\n",
       " '2375',\n",
       " '2376',\n",
       " '2377',\n",
       " '2378',\n",
       " '2379',\n",
       " '2380',\n",
       " '2381',\n",
       " '2382',\n",
       " '2383',\n",
       " '2384',\n",
       " '2385',\n",
       " '2386',\n",
       " '2387',\n",
       " '2388',\n",
       " '2389',\n",
       " '2390',\n",
       " '2391',\n",
       " '2392',\n",
       " '2393',\n",
       " '2394',\n",
       " '2395',\n",
       " '2396',\n",
       " '2397',\n",
       " '2398',\n",
       " '2399',\n",
       " '2400',\n",
       " '2401',\n",
       " '2402',\n",
       " '2403',\n",
       " '2404',\n",
       " '2405',\n",
       " '2406',\n",
       " '2407',\n",
       " '2408',\n",
       " '2409',\n",
       " '2410',\n",
       " '2411',\n",
       " '2412',\n",
       " '2413',\n",
       " '2414',\n",
       " '2415',\n",
       " '2416',\n",
       " '2417',\n",
       " '2418',\n",
       " '2419',\n",
       " '2420',\n",
       " '2421',\n",
       " '2422',\n",
       " '2423',\n",
       " '2424',\n",
       " '2425',\n",
       " '2426',\n",
       " '2427',\n",
       " '2428',\n",
       " '2429',\n",
       " '2430',\n",
       " '2431',\n",
       " '2432',\n",
       " '2433',\n",
       " '2434',\n",
       " '2435',\n",
       " '2436',\n",
       " '2437',\n",
       " '2438',\n",
       " '2439',\n",
       " '2440',\n",
       " '2441',\n",
       " '2442',\n",
       " '2443',\n",
       " '2444',\n",
       " '2445',\n",
       " '2446',\n",
       " '2447',\n",
       " '2448',\n",
       " '2449',\n",
       " '2450',\n",
       " '2451',\n",
       " '2452',\n",
       " '2453',\n",
       " '2454',\n",
       " '2455',\n",
       " '2456',\n",
       " '2457',\n",
       " '2458',\n",
       " '2459',\n",
       " '2460',\n",
       " '2461',\n",
       " '2462',\n",
       " '2463',\n",
       " '2464',\n",
       " '2465',\n",
       " '2466',\n",
       " '2467',\n",
       " '2468',\n",
       " '2469',\n",
       " '2470',\n",
       " '2471',\n",
       " '2472',\n",
       " '2473',\n",
       " '2474',\n",
       " '2475',\n",
       " '2476',\n",
       " '2477',\n",
       " '2478',\n",
       " '2479',\n",
       " '2480',\n",
       " '2481',\n",
       " '2482',\n",
       " '2483',\n",
       " '2484',\n",
       " '2485',\n",
       " '2486',\n",
       " '2487',\n",
       " '2488',\n",
       " '2489',\n",
       " '2490',\n",
       " '2491',\n",
       " '2492',\n",
       " '2493',\n",
       " '2494',\n",
       " '2495',\n",
       " '2496',\n",
       " '2497',\n",
       " '2498',\n",
       " '2499',\n",
       " '2500',\n",
       " '2501',\n",
       " '2502',\n",
       " '2503',\n",
       " '2504',\n",
       " '2505',\n",
       " '2506',\n",
       " '2507',\n",
       " '2508',\n",
       " '2509',\n",
       " '2510',\n",
       " '2511',\n",
       " '2512',\n",
       " '2513',\n",
       " '2514',\n",
       " '2515',\n",
       " '2516',\n",
       " '2517',\n",
       " '2518',\n",
       " '2519',\n",
       " '2520',\n",
       " '2521',\n",
       " '2522',\n",
       " '2523',\n",
       " '2524',\n",
       " '2525',\n",
       " '2526',\n",
       " '2527',\n",
       " '2528',\n",
       " '2529',\n",
       " '2530',\n",
       " '2531',\n",
       " '2532',\n",
       " '2533',\n",
       " '2534',\n",
       " '2535',\n",
       " '2536',\n",
       " '2537',\n",
       " '2538',\n",
       " '2539',\n",
       " '2540',\n",
       " '2541',\n",
       " '2542',\n",
       " '2543',\n",
       " '2544',\n",
       " '2545',\n",
       " '2546',\n",
       " '2547',\n",
       " '2548',\n",
       " '2549',\n",
       " '2550',\n",
       " '2551',\n",
       " '2552',\n",
       " '2553',\n",
       " '2554',\n",
       " '2555',\n",
       " '2556',\n",
       " '2557',\n",
       " '2558',\n",
       " '2559',\n",
       " '2560',\n",
       " '2561',\n",
       " '2562',\n",
       " '2563',\n",
       " '2564',\n",
       " '2565',\n",
       " '2566',\n",
       " '2567',\n",
       " '2568',\n",
       " '2569',\n",
       " '2570',\n",
       " '2571',\n",
       " '2572',\n",
       " '2573',\n",
       " '2574',\n",
       " '2575',\n",
       " '2576',\n",
       " '2577',\n",
       " '2578',\n",
       " '2579',\n",
       " '2580',\n",
       " '2581',\n",
       " '2582',\n",
       " '2583',\n",
       " '2584',\n",
       " '2585',\n",
       " '2586',\n",
       " '2587',\n",
       " '2588',\n",
       " '2589',\n",
       " '2590',\n",
       " '2591',\n",
       " '2592',\n",
       " '2593',\n",
       " '2594',\n",
       " '2595',\n",
       " '2596',\n",
       " '2597',\n",
       " '2598',\n",
       " '2599',\n",
       " '2600',\n",
       " '2601',\n",
       " '2602',\n",
       " '2603',\n",
       " '2604',\n",
       " '2605',\n",
       " '2606',\n",
       " '2607',\n",
       " '2608',\n",
       " '2609',\n",
       " '2610',\n",
       " ...]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = []\n",
    "for i in train_index:\n",
    "    a.append(i)\n",
    "a = list(map(str, a))\n",
    "a\n",
    "# a = np.char.lstrip(np.array(list(map(str,a))))\n",
    "# a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f7978c4-d1ee-4f16-b3c1-c8487ebb9be3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-22T07:11:43.039554Z",
     "iopub.status.busy": "2022-11-22T07:11:43.039554Z",
     "iopub.status.idle": "2022-11-22T07:11:43.089419Z",
     "shell.execute_reply": "2022-11-22T07:11:43.088421Z",
     "shell.execute_reply.started": "2022-11-22T07:11:43.039554Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Int64Index([ 1611,  1612,  1613,  1614,  1615,  1616,  1617,  1618,  1619,\\n             1620,\\n            ...\\n            11266, 11267, 11268, 11269, 11270, 11271, 11272, 11273, 11274,\\n            11275],\\n           dtype='int64', length=9665)] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_index\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mC:\\Ananconda3\\lib\\site-packages\\pandas\\core\\frame.py:3511\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3509\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3510\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 3511\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3513\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3514\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mC:\\Ananconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5796\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5793\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   5794\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5796\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5798\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   5799\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5800\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Ananconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5856\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[0;32m   5855\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 5856\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   5858\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   5859\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Int64Index([ 1611,  1612,  1613,  1614,  1615,  1616,  1617,  1618,  1619,\\n             1620,\\n            ...\\n            11266, 11267, 11268, 11269, 11270, 11271, 11272, 11273, 11274,\\n            11275],\\n           dtype='int64', length=9665)] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "X_train[train_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a18cadfc-cab6-463e-96a4-8ae099fc821b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-22T07:11:35.505508Z",
     "iopub.status.busy": "2022-11-22T07:11:35.504513Z",
     "iopub.status.idle": "2022-11-22T07:11:35.517476Z",
     "shell.execute_reply": "2022-11-22T07:11:35.517476Z",
     "shell.execute_reply.started": "2022-11-22T07:11:35.505508Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2, ..., 1608, 1609, 1610])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961854a6-d9b7-4a69-adc0-feb581bdd438",
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder_counter , (train_index, valid_index) in enumerate(kf.split(X_train)):\n",
    "    #입력된 학습 데이터에서 기반 모델이 학습/예측할 폴드 데이터 셋 추출 \n",
    "    X_tr = X_train[train_index] \n",
    "    y_tr = y_train[train_index] \n",
    "    X_te = X_train[valid_index]  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
